{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 00:00:02.584811: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-15 00:00:03.700810: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import keras_ocr\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_Data:\n",
    "    def __init__(self,pdf=None):\n",
    "        self.pdf = pdf\n",
    "        self.image_path = None\n",
    "        self.features_array = None\n",
    "        self.words_list=[]\n",
    "        self.word_box_list=[]\n",
    "        \n",
    "\n",
    "   \n",
    "\n",
    "        \n",
    "    def convert_to_img(self):\n",
    "        # Path to your PDF file\n",
    "        pdf_path = self.pdf\n",
    "\n",
    "        # Extract the PDF file name without extension\n",
    "        pdf_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "\n",
    "        # Open the PDF file\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "        # Iterate through each page in the PDF\n",
    "        for page_number in range(len(pdf_document)):\n",
    "            # Get the page\n",
    "            page = pdf_document.load_page(page_number)\n",
    "\n",
    "            # Convert the page to an image\n",
    "            pix = page.get_pixmap()\n",
    "\n",
    "            # Save the image with PDF file name added\n",
    "            image_path = f'{pdf_name}_page_{page_number + 1}.png'\n",
    "            pix.save(image_path)\n",
    "            self.image_path = image_path\n",
    "\n",
    "        # Close the PDF document\n",
    "        pdf_document.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def features_data(self):\n",
    "        model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "        # Initialize the OCR pipeline\n",
    "        pipeline = keras_ocr.pipeline.Pipeline()\n",
    "    \n",
    "        # Read the image\n",
    "        img_path = self.image_path\n",
    "        image = keras_ocr.tools.read(img_path)\n",
    "\n",
    "        if isinstance(image, list) and len(image) > 0:\n",
    "            image = image[0]  # Assuming the first element is the image data\n",
    "\n",
    "        # Perform OCR recognition\n",
    "        prediction_groups = pipeline.recognize([image])\n",
    "\n",
    "        # labels_list = []\n",
    "        features_list = []\n",
    "\n",
    "        # Extract font size from the LaTeX file\n",
    "        \n",
    "\n",
    "        \n",
    "        for predictions in prediction_groups:\n",
    "            for word, box in predictions:\n",
    "                # Convert box coordinates to integers\n",
    "                box = np.array(box, dtype=np.int32)\n",
    "                \n",
    "                box[2][1] += 3\n",
    "\n",
    "                # Extract region of interest (ROI) from the image\n",
    "                x_min, y_min = int(np.min(box[:, 0])), int(np.min(box[:, 1]))\n",
    "                x_max, y_max = int(np.max(box[:, 0])), int(np.max(box[:, 1]))\n",
    "\n",
    "                # Ensure that the bounding box coordinates are within the image boundaries\n",
    "                x_min = max(0, x_min)\n",
    "                y_min = max(0, y_min)\n",
    "                x_max = min(image.shape[1], x_max)\n",
    "                y_max = min(image.shape[0], y_max)\n",
    "\n",
    "                roi = image[y_min:y_max, x_min:x_max]\n",
    "\n",
    "                # Preprocess the ROI image for VGG16 model\n",
    "                roi_resized = cv2.resize(roi, (224, 224))  # Resize to match VGG16 input size\n",
    "                roi_resized = np.expand_dims(roi_resized, axis=0)  # Add batch dimension\n",
    "                roi_preprocessed = preprocess_input(roi_resized)  # Preprocess input for VGG16\n",
    "\n",
    "                # Extract features using VGG16 model\n",
    "                features = model.predict(roi_preprocessed)\n",
    "\n",
    "                # Store features and labels\n",
    "                # features_list.append(features)\n",
    "                features_list.append((word, features))\n",
    "                self.word_box_list.append((word, box))\n",
    "\n",
    "\n",
    "        # self.features_array = np.array(features_list)\n",
    "        self.features_array = np.array([f[1] for f in features_list])  # Extract only features for array\n",
    "        self.words_list = [f[0] for f in features_list]  # Extract words for list\n",
    "\n",
    "\n",
    "    #for making prediction based using trained model and extracted features\n",
    "    def prediction(self,model_style,model_size):\n",
    "        self.convert_to_img()\n",
    "        self.features_data()\n",
    "        features = self.features_array\n",
    "        features_flattened = features.reshape(features.shape[0], -1)\n",
    "        features_reshaped = features_flattened.reshape((-1, 112, 224, 1))\n",
    "        y_pred_svm = model_style.predict(features_flattened)\n",
    "        predicted_font_sizes = model_size.predict(features_reshaped)\n",
    "        \n",
    "        words_list = self.words_list\n",
    "\n",
    "        word_label_mapping = [(word,label,size) for word,label,size in zip(words_list, y_pred_svm,predicted_font_sizes)]\n",
    "        w_b_list=self.word_box_list\n",
    "\n",
    "        print(\"Number of word-box tuples:\", len(w_b_list))\n",
    "\n",
    "        return word_label_mapping,w_b_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 00:00:05.925136: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2024-05-15 00:00:05.925166: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: aditechbuddy-IdeaPad-Gaming-3-15ACH6\n",
      "2024-05-15 00:00:05.925173: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: aditechbuddy-IdeaPad-Gaming-3-15ACH6\n",
      "2024-05-15 00:00:05.925302: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 535.171.4\n",
      "2024-05-15 00:00:05.925321: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 535.171.4\n",
      "2024-05-15 00:00:05.925326: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 535.171.4\n"
     ]
    }
   ],
   "source": [
    "model_style= joblib.load('svm_8k.pkl')\n",
    "model_size=load_model('font_size_reg.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for /home/adi_techbuddy/.keras-ocr/craft_mlt_25k.h5\n",
      "Looking for /home/adi_techbuddy/.keras-ocr/crnn_kurapan.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 00:00:09.427070: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 513013760 exceeds 10% of free system memory.\n",
      "2024-05-15 00:00:09.590988: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 513013760 exceeds 10% of free system memory.\n",
      "2024-05-15 00:00:09.879265: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 513013760 exceeds 10% of free system memory.\n",
      "2024-05-15 00:00:10.286954: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 513013760 exceeds 10% of free system memory.\n",
      "2024-05-15 00:00:10.551979: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 128253440 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step\n",
      "4/4 [==============================] - 5s 1s/step\n",
      "1/1 [==============================] - 0s 207ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "4/4 [==============================] - 0s 81ms/step\n",
      "Number of word-box tuples: 121\n"
     ]
    }
   ],
   "source": [
    "# pdf_path='testing_pdfs/test1.pdf'\n",
    "pdf_path='image.pdf'\n",
    "data=Test_Data(pdf_path)  \n",
    "word_label_mapping,w_b_list = data.prediction(model_style,model_size)\n",
    "\n",
    "# print(word_label_mapping) #label size and font style(predicted)\n",
    "# print(w_b_list) #word and box size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements in the merged list: 121\n"
     ]
    }
   ],
   "source": [
    "merged_list = []\n",
    "\n",
    "# Iterate over both lists simultaneously using zip\n",
    "for (word, box), (word_label,label,size) in zip(w_b_list, word_label_mapping):\n",
    "    # Ensure that the words match\n",
    "    assert word == word_label, \"Words do not match between the two lists\"\n",
    "\n",
    "    size_str = str(np.round(size)[0])\n",
    "\n",
    "\n",
    "    # Append a tuple containing word, box, label, and features\n",
    "    merged_list.append((word, box,label,size_str))  \n",
    "\n",
    "# Print the number of elements in the merged list\n",
    "print(\"Number of elements in the merged list:\", len(merged_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('administration', array([[201, 142],\n",
      "       [311, 141],\n",
      "       [312, 162],\n",
      "       [202, 161]], dtype=int32), 'underline', '18.0'), ('branch', array([[312, 142],\n",
      "       [368, 142],\n",
      "       [368, 164],\n",
      "       [312, 161]], dtype=int32), 'underline', '15.0'), ('11', array([[446, 204],\n",
      "       [465, 204],\n",
      "       [465, 224],\n",
      "       [446, 221]], dtype=int32), 'normal', '10.0'), ('2010', array([[466, 204],\n",
      "       [497, 204],\n",
      "       [497, 223],\n",
      "       [466, 220]], dtype=int32), 'normal', '15.0'), ('12014', array([[196, 205],\n",
      "       [230, 205],\n",
      "       [230, 224],\n",
      "       [196, 221]], dtype=int32), 'normal', '15.0'), ('june', array([[415, 205],\n",
      "       [445, 205],\n",
      "       [445, 223],\n",
      "       [415, 220]], dtype=int32), 'italic', '12.0'), ('file', array([[ 72, 206],\n",
      "       [ 94, 206],\n",
      "       [ 94, 225],\n",
      "       [ 72, 222]], dtype=int32), 'normal', '13.0'), ('no', array([[ 96, 206],\n",
      "       [115, 206],\n",
      "       [115, 225],\n",
      "       [ 96, 222]], dtype=int32), 'normal', '11.0'), ('admn', array([[114, 206],\n",
      "       [151, 206],\n",
      "       [151, 225],\n",
      "       [114, 222]], dtype=int32), 'italic', '13.0'), ('limisc', array([[153, 205],\n",
      "       [196, 206],\n",
      "       [195, 225],\n",
      "       [152, 220]], dtype=int32), 'italic', '12.0'), ('office', array([[238, 265],\n",
      "       [287, 265],\n",
      "       [287, 287],\n",
      "       [238, 284]], dtype=int32), 'underline', '17.0'), ('order', array([[287, 265],\n",
      "       [334, 265],\n",
      "       [334, 287],\n",
      "       [287, 284]], dtype=int32), 'underline', '17.0'), ('prof', array([[360, 337],\n",
      "       [387, 337],\n",
      "       [387, 356],\n",
      "       [360, 353]], dtype=int32), 'normal', '12.0'), ('tiplut', array([[394, 337],\n",
      "       [427, 337],\n",
      "       [427, 358],\n",
      "       [394, 355]], dtype=int32), 'normal', '12.0'), ('nongbri', array([[432, 337],\n",
      "       [479, 337],\n",
      "       [479, 358],\n",
      "       [432, 355]], dtype=int32), 'italic', '16.0'), ('vice', array([[132, 337],\n",
      "       [163, 340],\n",
      "       [161, 358],\n",
      "       [130, 352]], dtype=int32), 'normal', '13.0'), ('chancellor', array([[160, 338],\n",
      "       [222, 338],\n",
      "       [222, 357],\n",
      "       [160, 354]], dtype=int32), 'normal', '14.0'), ('pleased', array([[242, 339],\n",
      "       [287, 337],\n",
      "       [288, 357],\n",
      "       [243, 356]], dtype=int32), 'italic', '13.0'), ('appoint', array([[310, 341],\n",
      "       [354, 337],\n",
      "       [356, 357],\n",
      "       [311, 357]], dtype=int32), 'italic', '14.0'), ('to', array([[293, 339],\n",
      "       [307, 339],\n",
      "       [307, 356],\n",
      "       [293, 353]], dtype=int32), 'normal', '13.0'), ('as', array([[485, 339],\n",
      "       [500, 339],\n",
      "       [500, 355],\n",
      "       [485, 352]], dtype=int32), 'normal', '10.0'), ('is', array([[226, 340],\n",
      "       [237, 340],\n",
      "       [237, 356],\n",
      "       [226, 353]], dtype=int32), 'normal', '11.0'), ('nonth', array([[469, 356],\n",
      "       [500, 356],\n",
      "       [500, 375],\n",
      "       [469, 372]], dtype=int32), 'italic', '13.0'), ('and', array([[360, 357],\n",
      "       [384, 357],\n",
      "       [384, 376],\n",
      "       [360, 373]], dtype=int32), 'normal', '13.0'), ('of', array([[432, 357],\n",
      "       [445, 357],\n",
      "       [445, 376],\n",
      "       [432, 373]], dtype=int32), 'normal', '11.0'), ('oificer', array([[110, 358],\n",
      "       [149, 358],\n",
      "       [149, 377],\n",
      "       [110, 374]], dtype=int32), 'italic', '14.0'), ('of', array([[221, 358],\n",
      "       [234, 358],\n",
      "       [234, 377],\n",
      "       [221, 374]], dtype=int32), 'normal', '14.0'), ('grievances', array([[256, 358],\n",
      "       [321, 356],\n",
      "       [322, 377],\n",
      "       [257, 377]], dtype=int32), 'italic', '13.0'), ('safety', array([[323, 356],\n",
      "       [360, 359],\n",
      "       [358, 379],\n",
      "       [322, 373]], dtype=int32), 'italic', '16.0'), ('the', array([[446, 358],\n",
      "       [466, 358],\n",
      "       [466, 376],\n",
      "       [446, 373]], dtype=int32), 'normal', '14.0'), ('nodal', array([[ 73, 359],\n",
      "       [108, 359],\n",
      "       [108, 378],\n",
      "       [ 73, 375]], dtype=int32), 'italic', '13.0'), ('lake', array([[164, 359],\n",
      "       [191, 359],\n",
      "       [191, 377],\n",
      "       [164, 374]], dtype=int32), 'normal', '11.0'), ('the', array([[235, 359],\n",
      "       [255, 359],\n",
      "       [255, 377],\n",
      "       [235, 374]], dtype=int32), 'normal', '14.0'), ('securty', array([[385, 359],\n",
      "       [430, 359],\n",
      "       [430, 378],\n",
      "       [385, 375]], dtype=int32), 'italic', '13.0'), ('to', array([[150, 360],\n",
      "       [164, 360],\n",
      "       [164, 377],\n",
      "       [150, 374]], dtype=int32), 'normal', '13.0'), ('care', array([[192, 361],\n",
      "       [219, 361],\n",
      "       [219, 377],\n",
      "       [192, 374]], dtype=int32), 'normal', '12.0'), ('and', array([[456, 377],\n",
      "       [479, 377],\n",
      "       [479, 396],\n",
      "       [456, 393]], dtype=int32), 'normal', '14.0'), ('will', array([[480, 377],\n",
      "       [500, 377],\n",
      "       [500, 396],\n",
      "       [480, 393]], dtype=int32), 'italic', '12.0'), ('jnu', array([[184, 377],\n",
      "       [211, 377],\n",
      "       [211, 397],\n",
      "       [184, 394]], dtype=int32), 'normal', '11.0'), ('nodal', array([[294, 378],\n",
      "       [328, 378],\n",
      "       [328, 397],\n",
      "       [294, 394]], dtype=int32), 'normal', '12.0'), ('oficer', array([[330, 378],\n",
      "       [368, 378],\n",
      "       [368, 397],\n",
      "       [330, 394]], dtype=int32), 'italic', '15.0'), ('will', array([[371, 378],\n",
      "       [390, 378],\n",
      "       [390, 396],\n",
      "       [371, 393]], dtype=int32), 'normal', '12.0'), ('liaison', array([[391, 378],\n",
      "       [428, 378],\n",
      "       [428, 396],\n",
      "       [391, 393]], dtype=int32), 'normal', '11.0'), ('with', array([[430, 378],\n",
      "       [454, 378],\n",
      "       [454, 396],\n",
      "       [430, 393]], dtype=int32), 'italic', '10.0'), ('eastern', array([[ 74, 379],\n",
      "       [118, 379],\n",
      "       [118, 398],\n",
      "       [ 74, 395]], dtype=int32), 'italic', '11.0'), ('students', array([[118, 379],\n",
      "       [169, 378],\n",
      "       [170, 396],\n",
      "       [119, 395]], dtype=int32), 'italic', '14.0'), ('in', array([[170, 379],\n",
      "       [183, 379],\n",
      "       [183, 397],\n",
      "       [170, 394]], dtype=int32), 'normal', '9.0'), ('the', array([[269, 379],\n",
      "       [292, 379],\n",
      "       [292, 397],\n",
      "       [269, 394]], dtype=int32), 'normal', '12.0'), ('campus', array([[213, 381],\n",
      "       [261, 381],\n",
      "       [261, 400],\n",
      "       [213, 397]], dtype=int32), 'normal', '14.0'), ('she', array([[454, 397],\n",
      "       [478, 397],\n",
      "       [478, 416],\n",
      "       [454, 413]], dtype=int32), 'normal', '17.0'), ('north', array([[328, 398],\n",
      "       [360, 398],\n",
      "       [360, 417],\n",
      "       [328, 414]], dtype=int32), 'italic', '13.0'), ('east', array([[364, 398],\n",
      "       [391, 398],\n",
      "       [391, 417],\n",
      "       [364, 414]], dtype=int32), 'normal', '15.0'), ('students', array([[393, 398],\n",
      "       [445, 398],\n",
      "       [445, 417],\n",
      "       [393, 414]], dtype=int32), 'italic', '15.0'), ('will', array([[481, 398],\n",
      "       [501, 398],\n",
      "       [501, 416],\n",
      "       [481, 413]], dtype=int32), 'normal', '13.0'), ('and', array([[196, 399],\n",
      "       [219, 399],\n",
      "       [219, 418],\n",
      "       [196, 415]], dtype=int32), 'normal', '15.0'), ('wellare', array([[244, 399],\n",
      "       [286, 398],\n",
      "       [287, 416],\n",
      "       [245, 415]], dtype=int32), 'normal', '13.0'), ('of', array([[289, 399],\n",
      "       [303, 399],\n",
      "       [303, 417],\n",
      "       [289, 414]], dtype=int32), 'normal', '13.0'), ('itne', array([[304, 399],\n",
      "       [324, 399],\n",
      "       [324, 417],\n",
      "       [304, 414]], dtype=int32), 'normal', '14.0'), ('look', array([[ 73, 400],\n",
      "       [ 99, 400],\n",
      "       [ 99, 418],\n",
      "       [ 73, 415]], dtype=int32), 'normal', '14.0'), ('into', array([[101, 400],\n",
      "       [124, 400],\n",
      "       [124, 418],\n",
      "       [101, 415]], dtype=int32), 'normal', '16.0'), ('tne', array([[126, 400],\n",
      "       [147, 400],\n",
      "       [147, 418],\n",
      "       [126, 415]], dtype=int32), 'normal', '17.0'), ('interest', array([[149, 400],\n",
      "       [194, 400],\n",
      "       [194, 418],\n",
      "       [149, 415]], dtype=int32), 'italic', '13.0'), ('tne', array([[221, 400],\n",
      "       [241, 400],\n",
      "       [241, 418],\n",
      "       [221, 415]], dtype=int32), 'normal', '15.0'), ('nodal', array([[377, 418],\n",
      "       [412, 418],\n",
      "       [412, 437],\n",
      "       [377, 434]], dtype=int32), 'normal', '13.0'), ('oficer', array([[414, 418],\n",
      "       [452, 418],\n",
      "       [452, 437],\n",
      "       [414, 434]], dtype=int32), 'italic', '15.0'), ('and', array([[173, 419],\n",
      "       [196, 419],\n",
      "       [196, 438],\n",
      "       [173, 435]], dtype=int32), 'normal', '12.0'), ('dayloday', array([[241, 419],\n",
      "       [302, 419],\n",
      "       [302, 440],\n",
      "       [241, 437]], dtype=int32), 'italic', '15.0'), ('affairs', array([[304, 419],\n",
      "       [343, 419],\n",
      "       [343, 438],\n",
      "       [304, 435]], dtype=int32), 'normal', '14.0'), ('the', array([[351, 419],\n",
      "       [374, 419],\n",
      "       [374, 437],\n",
      "       [351, 434]], dtype=int32), 'normal', '13.0'), ('will', array([[455, 419],\n",
      "       [474, 419],\n",
      "       [474, 436],\n",
      "       [455, 433]], dtype=int32), 'italic', '12.0'), ('also', array([[476, 419],\n",
      "       [501, 419],\n",
      "       [501, 437],\n",
      "       [476, 434]], dtype=int32), 'normal', '14.0'), ('share', array([[ 73, 420],\n",
      "       [107, 420],\n",
      "       [107, 438],\n",
      "       [ 73, 435]], dtype=int32), 'normal', '14.0'), ('their', array([[108, 420],\n",
      "       [136, 420],\n",
      "       [136, 438],\n",
      "       [108, 435]], dtype=int32), 'normal', '14.0'), ('handle', array([[199, 420],\n",
      "       [239, 420],\n",
      "       [239, 438],\n",
      "       [199, 435]], dtype=int32), 'italic', '15.0'), ('views', array([[138, 421],\n",
      "       [171, 421],\n",
      "       [171, 438],\n",
      "       [138, 435]], dtype=int32), 'italic', '14.0'), ('safety', array([[409, 437],\n",
      "       [446, 440],\n",
      "       [444, 460],\n",
      "       [407, 454]], dtype=int32), 'italic', '13.0'), ('and', array([[445, 440],\n",
      "       [468, 438],\n",
      "       [469, 456],\n",
      "       [446, 455]], dtype=int32), 'normal', '14.0'), ('other', array([[470, 439],\n",
      "       [501, 439],\n",
      "       [501, 457],\n",
      "       [470, 454]], dtype=int32), 'normal', '13.0'), ('for', array([[198, 440],\n",
      "       [216, 440],\n",
      "       [216, 459],\n",
      "       [198, 456]], dtype=int32), 'normal', '12.0'), ('sensitization', array([[216, 440],\n",
      "       [290, 440],\n",
      "       [290, 459],\n",
      "       [216, 456]], dtype=int32), 'normal', '14.0'), ('self', array([[292, 440],\n",
      "       [314, 440],\n",
      "       [314, 458],\n",
      "       [292, 455]], dtype=int32), 'normal', '11.0'), ('defence', array([[315, 439],\n",
      "       [364, 440],\n",
      "       [363, 459],\n",
      "       [314, 454]], dtype=int32), 'italic', '16.0'), ('organize', array([[ 72, 443],\n",
      "       [122, 439],\n",
      "       [123, 459],\n",
      "       [ 73, 460]], dtype=int32), 'italic', '15.0'), ('women', array([[366, 441],\n",
      "       [408, 441],\n",
      "       [408, 458],\n",
      "       [366, 455]], dtype=int32), 'italic', '16.0'), ('programmes', array([[125, 442],\n",
      "       [197, 442],\n",
      "       [197, 462],\n",
      "       [125, 459]], dtype=int32), 'normal', '15.0'), ('wellare', array([[ 74, 460],\n",
      "       [116, 460],\n",
      "       [116, 479],\n",
      "       [ 74, 476]], dtype=int32), 'italic', '11.0'), ('of', array([[167, 460],\n",
      "       [182, 460],\n",
      "       [182, 479],\n",
      "       [167, 476]], dtype=int32), 'normal', '11.0'), ('nonth', array([[203, 460],\n",
      "       [235, 460],\n",
      "       [235, 479],\n",
      "       [203, 476]], dtype=int32), 'italic', '12.0'), ('east', array([[237, 460],\n",
      "       [264, 460],\n",
      "       [264, 479],\n",
      "       [237, 476]], dtype=int32), 'normal', '13.0'), ('students', array([[264, 460],\n",
      "       [316, 460],\n",
      "       [316, 479],\n",
      "       [264, 476]], dtype=int32), 'italic', '12.0'), ('activities', array([[117, 461],\n",
      "       [167, 461],\n",
      "       [167, 479],\n",
      "       [117, 476]], dtype=int32), 'italic', '12.0'), ('the', array([[181, 461],\n",
      "       [201, 461],\n",
      "       [201, 479],\n",
      "       [181, 476]], dtype=int32), 'normal', '12.0'), ('urther', array([[426, 500],\n",
      "       [465, 500],\n",
      "       [465, 518],\n",
      "       [426, 515]], dtype=int32), 'italic', '12.0'), ('the', array([[133, 501],\n",
      "       [156, 501],\n",
      "       [156, 520],\n",
      "       [133, 517]], dtype=int32), 'normal', '14.0'), ('of', array([[196, 501],\n",
      "       [210, 501],\n",
      "       [210, 520],\n",
      "       [196, 517]], dtype=int32), 'normal', '12.0'), ('appointment', array([[210, 503],\n",
      "       [281, 497],\n",
      "       [282, 519],\n",
      "       [211, 521]], dtype=int32), 'italic', '14.0'), ('be', array([[303, 501],\n",
      "       [320, 501],\n",
      "       [320, 519],\n",
      "       [303, 516]], dtype=int32), 'normal', '12.0'), ('for', array([[320, 501],\n",
      "       [338, 501],\n",
      "       [338, 519],\n",
      "       [320, 516]], dtype=int32), 'normal', '11.0'), ('two', array([[339, 501],\n",
      "       [361, 501],\n",
      "       [361, 519],\n",
      "       [339, 516]], dtype=int32), 'normal', '15.0'), ('all', array([[410, 501],\n",
      "       [426, 501],\n",
      "       [426, 518],\n",
      "       [410, 515]], dtype=int32), 'normal', '10.0'), ('notice', array([[465, 501],\n",
      "       [501, 501],\n",
      "       [501, 518],\n",
      "       [465, 515]], dtype=int32), 'italic', '14.0'), ('tenure', array([[157, 502],\n",
      "       [195, 502],\n",
      "       [195, 520],\n",
      "       [157, 517]], dtype=int32), 'italic', '12.0'), ('will', array([[282, 502],\n",
      "       [302, 502],\n",
      "       [302, 519],\n",
      "       [282, 516]], dtype=int32), 'italic', '10.0'), ('or', array([[396, 502],\n",
      "       [411, 502],\n",
      "       [411, 519],\n",
      "       [396, 516]], dtype=int32), 'normal', '13.0'), ('years', array([[362, 503],\n",
      "       [395, 503],\n",
      "       [395, 522],\n",
      "       [362, 519]], dtype=int32), 'normal', '13.0'), ('whichever', array([[ 73, 521],\n",
      "       [132, 521],\n",
      "       [132, 540],\n",
      "       [ 73, 537]], dtype=int32), 'italic', '12.0'), ('is', array([[132, 521],\n",
      "       [143, 521],\n",
      "       [143, 539],\n",
      "       [132, 536]], dtype=int32), 'normal', '13.0'), ('earier', array([[145, 522],\n",
      "       [185, 522],\n",
      "       [185, 540],\n",
      "       [145, 537]], dtype=int32), 'normal', '11.0'), ('anthony', array([[432, 578],\n",
      "       [495, 578],\n",
      "       [495, 599],\n",
      "       [432, 596]], dtype=int32), 'normal', '14.0'), ('kh', array([[374, 580],\n",
      "       [395, 580],\n",
      "       [395, 600],\n",
      "       [374, 597]], dtype=int32), 'normal', '12.0'), ('sile', array([[398, 580],\n",
      "       [431, 580],\n",
      "       [431, 600],\n",
      "       [398, 597]], dtype=int32), 'normal', '15.0'), ('d', array([[495, 583],\n",
      "       [500, 583],\n",
      "       [500, 600],\n",
      "       [495, 597]], dtype=int32), 'normal', '9.0'), ('dy', array([[352, 600],\n",
      "       [372, 600],\n",
      "       [372, 620],\n",
      "       [352, 617]], dtype=int32), 'normal', '16.0'), ('registrar', array([[376, 600],\n",
      "       [451, 600],\n",
      "       [451, 621],\n",
      "       [376, 618]], dtype=int32), 'normal', '12.0'), ('admni', array([[451, 600],\n",
      "       [502, 600],\n",
      "       [502, 622],\n",
      "       [451, 619]], dtype=int32), 'italic', '14.0'), ('to', array([[ 75, 643],\n",
      "       [ 95, 643],\n",
      "       [ 95, 662],\n",
      "       [ 75, 659]], dtype=int32), 'normal', '14.0'), ('prof', array([[120, 663],\n",
      "       [148, 663],\n",
      "       [148, 682],\n",
      "       [120, 679]], dtype=int32), 'normal', '14.0'), ('nongbri', array([[184, 662],\n",
      "       [230, 664],\n",
      "       [229, 685],\n",
      "       [183, 681]], dtype=int32), 'normal', '16.0'), ('tiplut', array([[150, 664],\n",
      "       [183, 664],\n",
      "       [183, 684],\n",
      "       [150, 681]], dtype=int32), 'normal', '12.0'), ('csssisss', array([[119, 682],\n",
      "       [185, 682],\n",
      "       [185, 703],\n",
      "       [119, 700]], dtype=int32), 'normal', '19.0'), ('jnu', array([[119, 703],\n",
      "       [146, 703],\n",
      "       [146, 723],\n",
      "       [119, 720]], dtype=int32), 'normal', '14.0')]\n"
     ]
    }
   ],
   "source": [
    "print(merged_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Drawing boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line change at word: 11\n",
      "line change at word: office\n",
      "line change at word: prof\n",
      "line change at word: nonth\n",
      "line change at word: and\n",
      "line change at word: she\n",
      "line change at word: nodal\n",
      "line change at word: safety\n",
      "line change at word: wellare\n",
      "line change at word: urther\n",
      "line change at word: whichever\n",
      "line change at word: anthony\n",
      "line change at word: dy\n",
      "line change at word: to\n",
      "line change at word: prof\n",
      "line change at word: csssisss\n",
      "line change at word: jnu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for arrow and font charaterstics\n",
    "import random\n",
    "# image = cv2.imread('example_page_1.png')\n",
    "# image=cv2.imread('test7_page_1.png')\n",
    "image=cv2.imread('image_page_1.png')\n",
    "\n",
    "arrow_color = (0, 0, 255)  # White color for arrows\n",
    "arrow_thickness = 1\n",
    "\n",
    "dirn_r=True\n",
    "\n",
    "# Iterate over each word in the merged dictionary\n",
    "for i,(word, box, label, size) in enumerate(merged_list):\n",
    "    # Extract box coordinates and predicted font\n",
    "    \n",
    "    box = box.astype(int)\n",
    "\n",
    "\n",
    "    if(i==0):\n",
    "        y1=min(box[0][1],box[1][1])\n",
    "        y2=min(box[2][1],box[3][1])\n",
    "        l=label\n",
    "\n",
    "\n",
    "    if((min(box[0][1],box[1][1])-y1)<30):\n",
    "        # for keeping font same \n",
    "        label=l\n",
    "    else:\n",
    "        l=label\n",
    "\n",
    "\n",
    "    if(min(box[0][1],box[1][1])-y1>10):\n",
    "        # to change line so changing the y coordinate to bring uniformity\n",
    "        print(f\"line change at word: {word}\")\n",
    "        y1=min(box[0][1],box[1][1])\n",
    "        y2=min(box[2][1],box[3][1])\n",
    "\n",
    "    \n",
    "    \n",
    "    box[0][1]=y1\n",
    "    box[1][1]=y1\n",
    "\n",
    "    box[2][1]=y2\n",
    "    box[3][1]=y2\n",
    "\n",
    "\n",
    "    x = box[0][0]\n",
    "    y = box[0][1]\n",
    "    box_width = box[1][0] - box[0][0]\n",
    "\n",
    "\n",
    "    box[2][1]+=1\n",
    "\n",
    "\n",
    "    # Draw bounding box rectangle on the image\n",
    "    cv2.rectangle(image, (box[0][0], box[0][1]), (box[2][0], box[2][1]), (0, 255, 0), 2)\n",
    "\n",
    "    text_position = (box[0][0], box[0][1] - 20)\n",
    "    # arrow_start = (text_position[0] - random.randint(1,100), text_position[1])\n",
    "    arrow_end = (box[0][0], box[0][1])\n",
    "\n",
    "\n",
    "    if dirn_r:\n",
    "        arrow_start = (text_position[0] + random.randint(50, 100), text_position[1])\n",
    "        dirn_r=False\n",
    "    else:\n",
    "        arrow_start = (text_position[0] - random.randint(50, 100), text_position[1])\n",
    "        dirn_r=True\n",
    "#  \n",
    "\n",
    "    \n",
    "    if label=='bold':\n",
    "        a='b'\n",
    "        cv2.putText(image, f\"{a}{word}\", arrow_start,\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255,0,0), 1)\n",
    "    \n",
    "    elif label=='normal':\n",
    "        a='n'\n",
    "        cv2.putText(image, f\"{a}{word}\",arrow_start,\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,255,0), 1)\n",
    "    \n",
    "    elif label=='italic':\n",
    "        a='i'\n",
    "        cv2.putText(image, f\"{a}{word}\", arrow_start,\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,255), 1)\n",
    "    \n",
    "\n",
    "    elif label=='underline':\n",
    "        a='u'\n",
    "        cv2.putText(image, f\"{a}{word}\", arrow_start,\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,0), 1)\n",
    "    \n",
    "    \n",
    "    cv2.arrowedLine(image, arrow_start, arrow_end, arrow_color, arrow_thickness)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "cv2.imwrite('eg4_witharr.jpg',image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install googletrans==3.1.0a0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Translation on the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from googletrans import Translator\n",
    "# translator=Translator()\n",
    "# word='hello'\n",
    "\n",
    "# conv_word = translator.translate(word, dest=\"hi\")\n",
    "# print(conv_word.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(merged_list[0][1])\n",
    "# print(merged_list[0][1][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for word, box, label, size in merged_list:\n",
    "    # print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Clearing background from text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for /home/adi_techbuddy/.keras-ocr/craft_mlt_25k.h5\n",
      "Looking for /home/adi_techbuddy/.keras-ocr/crnn_kurapan.h5\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "4/4 [==============================] - 10s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_ocr\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "#General Approach.....\n",
    "#Use keras OCR to detect text, define a mask around the text, and inpaint the\n",
    "#masked regions to remove the text.\n",
    "#To apply the mask we need to provide the coordinates of the starting and \n",
    "#the ending points of the line, and the thickness of the line\n",
    "\n",
    "#The start point will be the mid-point between the top-left corner and \n",
    "#the bottom-left corner of the box. \n",
    "#the end point will be the mid-point between the top-right corner and the bottom-right corner.\n",
    "#The following function does exactly that.\n",
    "def midpoint(x1, y1, x2, y2):\n",
    "    x_mid = int((x1 + x2)/2)\n",
    "    y_mid = int((y1 + y2)/2)\n",
    "    return (x_mid, y_mid)\n",
    "\n",
    "#Main function that detects text and inpaints. \n",
    "#Inputs are the image path and kreas_ocr pipeline\n",
    "def inpaint_text(img_path, pipeline):\n",
    "    # read the image \n",
    "    img = keras_ocr.tools.read(img_path) \n",
    "    \n",
    "    # Recogize text (and corresponding regions)\n",
    "    # Each list of predictions in prediction_groups is a list of\n",
    "    # (word, box) tuples. \n",
    "    prediction_groups = pipeline.recognize([img])\n",
    "    \n",
    "    #Define the mask for inpainting\n",
    "    mask = np.zeros(img.shape[:2], dtype=\"uint8\")\n",
    "    for box in prediction_groups[0]:\n",
    "        x0, y0 = box[1][0]\n",
    "        x1, y1 = box[1][1] \n",
    "        x2, y2 = box[1][2]\n",
    "        x3, y3 = box[1][3] \n",
    "        \n",
    "        x_mid0, y_mid0 = midpoint(x1, y1, x2, y2)\n",
    "        x_mid1, y_mi1 = midpoint(x0, y0, x3, y3)\n",
    "        \n",
    "        #For the line thickness, we will calculate the length of the line between \n",
    "        #the top-left corner and the bottom-left corner.\n",
    "        thickness = int(math.sqrt( (x2 - x1)**2 + (y2 - y1)**2 ))\n",
    "        \n",
    "        #Define the line and inpaint\n",
    "        cv2.line(mask, (x_mid0, y_mid0), (x_mid1, y_mi1), 255,    \n",
    "        thickness)\n",
    "        inpainted_img = cv2.inpaint(img, mask, 7, cv2.INPAINT_NS)\n",
    "                 \n",
    "    return(inpainted_img)\n",
    "\n",
    "# keras-ocr will automatically download pretrained\n",
    "# weights for the detector and recognizer.\n",
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "\n",
    "# img_text_removed = inpaint_text('test2_page_1.png', pipeline)\n",
    "img_text_removed=inpaint_text('image_page_1.png',pipeline)\n",
    "\n",
    "# plt.imshow(img_text_removed)\n",
    "\n",
    "\n",
    "cv2.imwrite('text_removed_image.jpg', cv2.cvtColor(img_text_removed, cv2.COLOR_BGR2RGB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Font Size: 13.272727272727273\n"
     ]
    }
   ],
   "source": [
    "total_size = 0\n",
    "count = 0\n",
    "for i, (word, box, label, size) in enumerate(merged_list):\n",
    "\n",
    "    total_size += int(float(size))\n",
    "    count += 1\n",
    "\n",
    "average_size = total_size / count\n",
    "print(\"Average Font Size:\", average_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line change at word: 11\n",
      "line change at word: office\n",
      "line change at word: prof\n",
      "line change at word: nonth\n",
      "line change at word: and\n",
      "line change at word: she\n",
      "line change at word: nodal\n",
      "line change at word: safety\n",
      "line change at word: wellare\n",
      "line change at word: urther\n",
      "line change at word: whichever\n",
      "line change at word: anthony\n",
      "line change at word: dy\n",
      "line change at word: to\n",
      "line change at word: prof\n",
      "line change at word: csssisss\n",
      "line change at word: jnu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "from googletrans import Translator\n",
    "\n",
    "# Initialize translator\n",
    "translator = Translator()\n",
    "\n",
    "# Load the background image with PIL\n",
    "# bg_image = Image.open('test2/text_removed_image.jpg')\n",
    "bg_image=img_text_removed\n",
    "\n",
    "# Convert background image to numpy array\n",
    "bg_np = np.array(bg_image)\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('image_page_1.png')\n",
    "height, width, channels = image.shape \n",
    "# to get the actual dimension of the image we want to modify\n",
    "\n",
    "\n",
    "\n",
    "# Create a list to store the PIL images with text\n",
    "images_with_text = []\n",
    "\n",
    "ut=2\n",
    "\n",
    "for i,(word, box, label, size) in enumerate(merged_list):\n",
    "\n",
    "    # Extract box coordinates and predicted font\n",
    "    box = box.astype(int)\n",
    "    \n",
    "    if(i==0):\n",
    "        y1=min(box[0][1],box[1][1])\n",
    "        y2=min(box[2][1],box[3][1])\n",
    "        l=label\n",
    "\n",
    "\n",
    "    if((min(box[0][1],box[1][1])-y1)<30):\n",
    "        # for keeping font same \n",
    "        label=l\n",
    "    else:\n",
    "        l=label\n",
    "\n",
    "\n",
    "    if(min(box[0][1],box[1][1])-y1>10):\n",
    "        # to change line so changing the y coordinate to bring uniformity\n",
    "        print(f\"line change at word: {word}\")\n",
    "        y1=min(box[0][1],box[1][1])\n",
    "        y2=min(box[2][1],box[3][1])\n",
    "\n",
    "    \n",
    "    \n",
    "    box[0][1]=y1\n",
    "    box[1][1]=y1\n",
    "\n",
    "    box[2][1]=y2\n",
    "    box[3][1]=y2\n",
    "\n",
    "\n",
    "    x = box[0][0]\n",
    "    y = box[0][1]\n",
    "    box_width = box[1][0] - box[0][0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # print(word)\n",
    "    conv_word = translator.translate(word, dest=\"en\")\n",
    "    text = conv_word.text\n",
    "\n",
    "    # Define font size\n",
    "    font_size=average_size\n",
    "    # number_float = float(size)\n",
    "    # font_size = int(number_float)\n",
    "\n",
    "\n",
    "    # Font settings\n",
    "    if label=='normal':\n",
    "        font_path = 'fontstyle/notosans.ttf'\n",
    "        # font_path = 'fontstyle/CenturyStd-Light.ttf'\n",
    "    if label=='italic':\n",
    "        font_path='fontstyle/notosans_italic.ttf'\n",
    "        # font_path= 'fontstyle/CenturyStd-LightItalic.ttf'\n",
    "    if label=='bold':\n",
    "        font_path='fontstyle/notosans_bold.ttf'\n",
    "        # font_path = 'fontstyle/CenturyStd-Bold.ttf'\n",
    "    if label =='underline':\n",
    "        font_path='fontstyle/notosans.ttf'\n",
    "        # font_path='fontstyle/CenturyStd-Light.ttf'\n",
    "\n",
    "    # # for compressing to fit\n",
    "    # while True:\n",
    "    #     font = ImageFont.truetype(font_path, font_size)\n",
    "    #     text_width = draw.textlength(text, font=font)\n",
    "        \n",
    "    #     if text_width <= box_width:\n",
    "    #         break  # Exit the loop if the text fits within the box width\n",
    "        \n",
    "    #     font_size -= 1  # Decrease font size by 1 and try again\n",
    "\n",
    "    # # Truncate or split text to fit within box width\n",
    "    # while len(text) > 0 and text_width > box_width:\n",
    "    #     text = text[:-1]  # Remove the last character\n",
    "    #     text_width  = draw.textlength(text, font=font)\n",
    "\n",
    "\n",
    "    \n",
    "    # Create PIL image and draw text\n",
    "    if i==0:\n",
    "        pil_image = Image.fromarray(bg_np)  # Use background image\n",
    "    else:\n",
    "        pil_image = Image.fromarray(images_with_text[-1])  # Create a copy of the previous image\n",
    "    draw = ImageDraw.Draw(pil_image)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "    text_color = (0, 0, 0)\n",
    "    \n",
    "    # Draw text on PIL image\n",
    "    draw.text((x, y), text, fill=text_color, font=font)\n",
    "    \n",
    "    # Convert PIL image back to OpenCV format and store in the list\n",
    "    images_with_text.append(cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR))\n",
    "\n",
    "\n",
    "    if label == 'underline':\n",
    "        # print(word)\n",
    "        underline_start = (box[3][0], box[3][1]+2+ ut)\n",
    "        underline_end = (box[2][0], box[3][1]+2+ut)\n",
    "        cv2.line(images_with_text[-1], underline_start, underline_end, (0, 0, 0), 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "cv2.imwrite('test_f2_eng.png', images_with_text[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mycondaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
